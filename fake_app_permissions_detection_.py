# -*- coding: utf-8 -*-
"""Fake App Permissions Detection .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t5zVQSDPnIPWPYbFFx2QqXJlMrCtyGHb
"""

!pip install xgboost

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

data = pd.read_csv("/content/drive/MyDrive/ML_LAB/data.csv")

# Quick check
print(data.head())
print(data.info())
print("\nColumns:", data.columns)

# Target column is 'Result'
target_col = 'Result'

# Encode target: benign=0, malware=1
le = LabelEncoder()
data[target_col] = le.fit_transform(data[target_col])

# Split features and target
X = data.drop([target_col], axis=1)
y = data[target_col]

print("\nTarget Value Counts:")
print(y.value_counts())

# Step 1: Variance Threshold
var_thresh = VarianceThreshold(threshold=0.01)
X_var = var_thresh.fit_transform(X)
print(f'Original Features: {X.shape[1]}, After Variance Threshold: {X_var.shape[1]}')

# Step 2: Chi-Square - top 20 features
kbest = SelectKBest(score_func=chi2, k=20)
X_chi2 = kbest.fit_transform(X_var, y)
print(f'Top 20 Features Shape: {X_chi2.shape}')

X_train, X_test, y_train, y_test = train_test_split(
    X_pca, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}")

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)

def evaluate_model(y_true, y_pred, model_name):
    print(f"\n--- {model_name} Evaluation ---")
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred))
    print("Recall:", recall_score(y_true, y_pred))
    print("F1-Score:", f1_score(y_true, y_pred))
    print("Classification Report:\n", classification_report(y_true, y_pred))

    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{model_name} Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

evaluate_model(y_test, y_pred_rf, 'Random Forest')
evaluate_model(y_test, y_pred_xgb, 'XGBoost')

# --- Corrected Feature Importance Cell ---

# Keep column names after VarianceThreshold
var_feature_names = X.columns[var_thresh.get_support()]

# Get top 20 features selected by Chi-Square
X_selected = X_var[:, kbest.get_support()]  # Selected feature values
selected_feature_names = var_feature_names[kbest.get_support()]  # Corresponding names

# Optional: Train-test split for evaluation
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, random_state=42, stratify=y
)

# Train Random Forest on selected features
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# Evaluate model
from sklearn.metrics import accuracy_score, classification_report
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

# Plot feature importance with actual permission names
plt.figure(figsize=(12,6))
importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]
plt.bar(range(len(importances)), importances[indices])
plt.xticks(range(len(importances)), [selected_feature_names[i] for i in indices], rotation=90)
plt.title('Feature Importance - Random Forest (Top 20 Permissions)')
plt.show()

joblib.dump(rf, 'rf_permissions_model.pkl')
joblib.dump(xgb, 'xgb_permissions_model.pkl')

pd.DataFrame(y_pred_rf, columns=['RF_Prediction']).to_csv('rf_predictions.csv', index=False)
pd.DataFrame(y_pred_xgb, columns=['XGB_Prediction']).to_csv('xgb_predictions.csv', index=False)

print("All done! Models trained, evaluated, and saved.")